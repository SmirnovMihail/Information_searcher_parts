{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queries_list(file_name='queries_all.txt'):\n",
    "    \n",
    "    queries = []\n",
    "#     correct = dict()\n",
    "    correct = []\n",
    "    f = open(file_name)\n",
    "    num = 0\n",
    "    \n",
    "    for query in f:\n",
    "        \n",
    "        query = query.lower()\n",
    "        separated = query.split(sep='\\t')\n",
    "        \n",
    "        if len(separated) == 2:\n",
    "#             correct[separated[1][:-1]] = num\n",
    "            correct.append((separated[0], separated[1][:-1]))\n",
    "            queries.append(separated[1])\n",
    "            \n",
    "        else:\n",
    "            queries.append(separated[0][:-1])\n",
    "            \n",
    "        num +=1\n",
    "    \n",
    "    return queries, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    result = []\n",
    "#     print('x = ', x)\n",
    "    for elem in x:\n",
    "        if hasattr(elem, \"__iter__\") and not isinstance(elem, str) and not isinstance(elem, tuple) and len(elem)>1:\n",
    "            result.extend(flatten(elem))\n",
    "        else:\n",
    "            result.append(elem)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_concat(list1, list2):\n",
    "    \n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    \n",
    "    return [[list1[i], list2[j]] for i in range(len1) for j in range(len2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(params):\n",
    "    \n",
    "    list_ = params\n",
    "#     for value in params.values():\n",
    "#         list_.append(value)\n",
    "#     print(list_)\n",
    "    tmp = reduce(lambda x, y: list_concat(x, y), list_)\n",
    "    \n",
    "    res = []\n",
    "    for elem in tmp:\n",
    "        param_list = flatten([elem])\n",
    "#         print(param_list)\n",
    "#         param_dict = list(zip(params.keys(), param_list))\n",
    "        res.append(param_list)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node():\n",
    "    \n",
    "    def __init__(self, level :int = -1, letter = None, N = 10):\n",
    "        \n",
    "        self.children = dict('')\n",
    "        self.word = ''\n",
    "        self.level = level\n",
    "        self.letter = letter\n",
    "        self.available = set('ьнс')\n",
    "        self.N = N\n",
    "    \n",
    "    \n",
    "    def language(self, word):\n",
    "        \n",
    "        eng = \"qwertyuiop[]asdfghjkl;'zxcvbnm,\"\n",
    "        rus = \"йцукенгшщзхъфывапролджэячсмитьб\"\n",
    "        rus_transfer = dict(zip(rus, eng))\n",
    "        eng_transfer = dict(zip(eng, rus))\n",
    "        \n",
    "        keyboard, keyboard_t = (eng, eng_transfer) if word[0] in eng else (rus, rus_transfer)\n",
    "\n",
    "        for i in range(len(word)):\n",
    "            if word[i] not in keyboard:\n",
    "                return False, word\n",
    "\n",
    "        for i in range(len(word)):\n",
    "            word = word[:i] + keyboard_t[word[i]] + word[i+1:]\n",
    "            \n",
    "        return True, word\n",
    "                \n",
    "        \n",
    "    def add(self, word, position=0):\n",
    "        \n",
    "        if len(word) == position:\n",
    "            self.word = word\n",
    "            \n",
    "        else:   \n",
    "            if word[position] not in self.children.keys():\n",
    "                self.children[word[position]] = node(self.level+1, word[position], self.N)\n",
    "                \n",
    "            self.children[word[position]].add(word, position + 1)\n",
    "    \n",
    "    \n",
    "    def recount_probabilities(self, word, p, prev_letter):\n",
    "        \n",
    "        if self.level != -1:\n",
    "\n",
    "            if self.letter == word[self.level]:\n",
    "                new_p = p\n",
    "            elif word[self.level] not in changes_dict or self.letter not in changes_dict[word[self.level]]:\n",
    "                new_p = 0\n",
    "            elif self.level == 0:\n",
    "                new_p = p * sum(changes_dict[word[self.level]][self.letter].values())\n",
    "            elif prev_letter not in changes_dict[word[self.level]][self.letter].keys():\n",
    "                new_p = 0\n",
    "            else:\n",
    "                new_p = p * changes_dict[word[self.level]][self.letter][prev_letter]\n",
    "        else:\n",
    "            new_p = p\n",
    "            \n",
    "        return new_p\n",
    "    \n",
    "    \n",
    "    def search_after_adding_letter(self, word, p, letter, prev_letter, letter_deleted):\n",
    "\n",
    "        result = []\n",
    "        condition = letter in inserts_dict.keys() and prev_letter in inserts_dict[letter].keys()\n",
    "\n",
    "        if self.level > 0 and condition and not letter_deleted:\n",
    "\n",
    "            word_after_insertion = word[:self.level+1] + letter + word[self.level+1:]\n",
    "            insertion_p = p * inserts_dict[letter][prev_letter]/3 #3\n",
    "            result += self.children[letter].search(word_after_insertion, insertion_p, self.letter, True)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def search(self, word, p=1, prev_letter='', letter_added=False, letter_deleted=False, split=False):\n",
    "\n",
    "        result = []\n",
    "        p = self.recount_probabilities(word, p, prev_letter)\n",
    "\n",
    "        if self.level == -1:\n",
    "            for i in './+-=:':\n",
    "                if i in word:\n",
    "                    return []\n",
    "\n",
    "        if p <= 1.0e-15:\n",
    "            return []\n",
    "\n",
    "        if self.level+1 == len(word):\n",
    "\n",
    "            for node_letter in self.children:\n",
    "                result += self.search_after_adding_letter(word, p, node_letter, self.letter, letter_deleted)\n",
    "\n",
    "            result += [(self.word, p)] if self.word != '' else []\n",
    "\n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            for node_letter in self.children:\n",
    "                result += self.search_after_adding_letter(word, p, node_letter, prev_letter, letter_deleted)\n",
    "                result += self.children[node_letter].search(word, p, self.letter)\n",
    "\n",
    "            if not letter_added and not letter_deleted:\n",
    "\n",
    "                condition = self.letter in deletes_dict and prev_letter in deletes_dict[self.letter]\n",
    "\n",
    "                if self.level >= 0 and condition:\n",
    "                    d_p = p * deletes_dict[self.letter][prev_letter]/3\n",
    "                    word_after_delete = word[:self.level] + word[self.level+1:]\n",
    "                    result += self.search(word_after_delete, d_p, prev_letter, True, True)\n",
    "\n",
    "        if self.level == -1:\n",
    "\n",
    "            changed = self.language(word)\n",
    "\n",
    "            if changed[0]:\n",
    "                changed_word = changed[1]\n",
    "\n",
    "                for node_letter in self.children:\n",
    "                    result += self.children[node_letter].search(changed_word, p*med)\n",
    "\n",
    "#             if len(result) == 0 and split == False:\n",
    "\n",
    "#                 for split in range(1, len(word)):\n",
    "\n",
    "#                     c = 1#0.04**abs(split-len(word)/2)\n",
    "\n",
    "#                     r1 = self.search(word[:split], med*c/5, self.letter, split=True)\n",
    "#                     r2 = self.search(word[split:], med*c/5, self.letter, split=True)\n",
    "\n",
    "#                     r1 = r1 if r1 != [] else [(word[:split], 0)]\n",
    "#                     r2 = r2 if r2 != [] else [(word[split:], 0)]\n",
    "\n",
    "#                     p = r1[0][1] * r2[0][1]\n",
    "#                     result += [(r1[0][0] + ' ' + r2[0][0], p)] if  p != 0 else []\n",
    "\n",
    "        result.sort(key=lambda x: x[1])\n",
    "        result = result[::-1]\n",
    "\n",
    "        return result[:self.N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bore_search_tree():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.main_node = node()\n",
    "        \n",
    "        \n",
    "    def fit(self, words, freqs_sum, bigrams, bigrams_freqs_sum):\n",
    "        \n",
    "        self.words = words\n",
    "        self.freqs_sum = freqs_sum\n",
    "        self.bigrams_freqs_sum = bigrams_freqs_sum\n",
    "        self.bigrams = bigrams\n",
    "\n",
    "        for word in words.keys():\n",
    "            self.main_node.add(word)\n",
    "    \n",
    "    \n",
    "    def recount_probabilities(self, words, p, alpha=0.6):\n",
    "        \n",
    "        freq = 0\n",
    "\n",
    "        for word_ in words.split():\n",
    "            if word_ not in self.words:\n",
    "                freq += 1 / self.freqs_sum\n",
    "            else:\n",
    "                freq += self.words[word_] / self.freqs_sum\n",
    "\n",
    "        new_p = alpha*np.log(freq) + np.log(p)\n",
    "        \n",
    "        return words, new_p\n",
    "        \n",
    "    \n",
    "    def search(self, word, top=10, alpha=0.6):\n",
    "        \n",
    "        res = self.main_node.search(word)[:top]\n",
    "\n",
    "        for i in range(len(res)):\n",
    "            res[i] = self.recount_probabilities(res[i][0], res[i][1], alpha)\n",
    "        \n",
    "        res.sort(key = lambda x: x[1])\n",
    "        if res == []:\n",
    "            res.append((word, 1))\n",
    "\n",
    "        return res[::-1]\n",
    "    \n",
    "    \n",
    "    def multisearch(self, words_list, top=10, alpha=0.6):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        for word in words_list:\n",
    "            res.append(self.search(word, top, alpha))\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    \n",
    "    def bigrams_with_probabilities(self, samples):\n",
    "        \n",
    "        res = []\n",
    "\n",
    "        for sample in samples:\n",
    "            if len(sample) > 1:\n",
    "                for i in range(len(sample)-1, 0, -1):\n",
    "\n",
    "                    bigram = sample[i-1][0] + ' ' + sample[i][0]\n",
    "\n",
    "                    if bigram in self.bigrams:\n",
    "                        freq = self.bigrams[bigram]\n",
    "                    else:\n",
    "                        freq = np.log(1/self.bigrams_freqs_sum)\n",
    "\n",
    "                    sample.insert(i, (bigram, freq))\n",
    "\n",
    "            res.append(sample)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    \n",
    "    def answer_words_concatination(self, samples):\n",
    "    \n",
    "        final_res = []\n",
    "    \n",
    "        for sample in samples:\n",
    "\n",
    "            fix = str()\n",
    "            p = 0\n",
    "\n",
    "            for i in range(0, len(sample), 2):\n",
    "                fix += sample[i][0] + ' '\n",
    "\n",
    "            for i in range(len(sample)):\n",
    "                p += sample[i][1]\n",
    "\n",
    "            final_res.append((fix[:-1], p))\n",
    "        \n",
    "        return final_res\n",
    "    \n",
    "    \n",
    "    def classifier(self, answer):\n",
    "        \n",
    "        samples = combinations(answer)\n",
    "        \n",
    "        samples_with_bigrams = self.bigrams_with_probabilities(samples)\n",
    "        \n",
    "        generated_queries = self.answer_words_concatination(samples_with_bigrams)\n",
    "        generated_queries.sort(key = lambda x: x[1])\n",
    "        generated_queries = generated_queries[::-1]\n",
    "    \n",
    "        return generated_queries[:10]\n",
    "    \n",
    "    \n",
    "    def correct_query(self, query, alpha=1.5):\n",
    "        \n",
    "        query = query.lower()\n",
    "        words = query.split()\n",
    "        \n",
    "        answer = self.multisearch(words, alpha=alpha)\n",
    "        \n",
    "        words_num = len(words)\n",
    "        num = 1 if words_num > 15 else 2 if words_num > 9 else 10 - words_num\n",
    "\n",
    "        for i in range(len(answer)):\n",
    "            answer[i] = answer[i][:num]\n",
    "#         print(answer)\n",
    "        bests = self.classifier(answer)\n",
    "        \n",
    "        return bests[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_model():\n",
    "    \n",
    "    def __init__(self, queries):\n",
    "        \n",
    "        self.make_vectorizer(queries)\n",
    "        self.bigrams_freqs(queries)\n",
    "        \n",
    "        \n",
    "    def make_vectorizer(self, queries):\n",
    "        \n",
    "        vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        X = vectorizer.fit_transform(queries)\n",
    "        \n",
    "        words = vectorizer.get_feature_names()\n",
    "        freqs = np.array(X.sum(axis=0))[0]\n",
    "        \n",
    "        self.freqs_sum = freqs.sum()\n",
    "    \n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i][:20]\n",
    "          \n",
    "        self.words = dict(zip(words[50:474500], freqs[50:474500]))\n",
    "        \n",
    "        \n",
    "    def bigrams_freqs(self, queries):\n",
    "    \n",
    "        vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "        X = vectorizer.fit_transform(queries) \n",
    "\n",
    "        names = vectorizer.get_feature_names()\n",
    "        freqs = np.array(X.sum(axis=0))[0]\n",
    "\n",
    "        bad = np.where(freqs==1)[0][::-1]\n",
    "        for idx in bad:\n",
    "            names.pop(idx)\n",
    "\n",
    "        self.bigrams_freqs_sum = freqs.sum()    \n",
    "        freqs = freqs[np.where(freqs>1)[0]]/self.bigrams_freqs_sum\n",
    "    \n",
    "    #     res = []\n",
    "    #     for i in range(freqs.shape[0]):\n",
    "    #         res.append((names[i], freqs[i]/freqs_sum))\n",
    "        self.bigrams = dict(zip(names, freqs))\n",
    "    \n",
    "    \n",
    "    def get_bigrams(self):\n",
    "        \n",
    "        return self.bigrams, self.bigrams_freqs_sum\n",
    "    \n",
    "    \n",
    "    def get_words(self):\n",
    "        \n",
    "        return self.words, self.freqs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mistakes_model():\n",
    "    \n",
    "    def __init__(self, mistakes_with_correctings):\n",
    "        \n",
    "        self.mistakes_with_correctings = mistakes_with_correctings\n",
    "        \n",
    "        self.main_changes_dict = dict()\n",
    "        self.main_inserts_dict = dict()\n",
    "        self.main_deletes_dict = dict()\n",
    "        \n",
    "        self.dicts_making()\n",
    "        \n",
    "        self.main_changes_dict, self.changes_med, self.changes_mean = self.process_dict(self.main_changes_dict, 70)\n",
    "        self.main_inserts_dict, self.inserts_med, self.inserts_mean = self.process_dict(self.main_inserts_dict,50)\n",
    "        self.main_deletes_dict, self.deletes_med, self.deletes_mean = self.process_dict(self.main_deletes_dict,100)\n",
    "        \n",
    "        self.final_changes_dict_maker()\n",
    "        self.final_inserts_dict_maker()\n",
    "        self.final_deletes_dict_maker()\n",
    "\n",
    "    \n",
    "    def language_check(self, word1, word2):\n",
    "    \n",
    "        letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz0123456789'\n",
    "\n",
    "        for i in word1 + word2:\n",
    "            if i not in letters:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "        \n",
    "    def levenstein_dist(self, word1, word2):\n",
    "        main_matrix = np.zeros((len(word1)+1, len(word2)+1))\n",
    "\n",
    "        for i in range(1, main_matrix.shape[0]):\n",
    "            main_matrix[i, 0] = i\n",
    "\n",
    "        for i in range(1, main_matrix.shape[1]):\n",
    "            main_matrix[0, i] = i    \n",
    "\n",
    "        for i in range(1, main_matrix.shape[0]):\n",
    "            for j in range(1, main_matrix.shape[1]):\n",
    "\n",
    "                minimum = min(main_matrix[i, j-1], main_matrix[i-1, j], main_matrix[i-1, j-1])\n",
    "\n",
    "                if word1[i-1] == word2[j-1]:\n",
    "                    main_matrix[i, j] = minimum\n",
    "                else:\n",
    "                    main_matrix[i, j] = minimum + 1\n",
    "\n",
    "        return main_matrix        \n",
    "        \n",
    "\n",
    "    def stats(self, m):\n",
    "\n",
    "        if m.shape[0] == 1 and m.shape[1] == 1:\n",
    "            return []\n",
    "\n",
    "        curr = m[-1, -1]\n",
    "        res = []\n",
    "        info = [0, 0, 0]\n",
    "\n",
    "        if m.shape[0] > 1 and m[-2, -1] <= curr:\n",
    "            res += [[m.shape[0]-2, m.shape[1]-1, -1]]\n",
    "            info[0] = 1\n",
    "\n",
    "        if m.shape[1] > 1 and m[-1, -2] <= curr:\n",
    "            res += [[m.shape[0]-1, m.shape[1]-2,  1]]\n",
    "            info[1] = 1\n",
    "\n",
    "        if m.shape[0] > 1 and m.shape[1] > 1 and m[-2, -2] <= curr:\n",
    "            res += [[m.shape[0]-2, m.shape[1]-2, 0]] \n",
    "            info[2] = 1\n",
    "\n",
    "        if info[2] == 1:\n",
    "            res += self.stats(m[:-1, :-1])\n",
    "        else:\n",
    "            if info[0] == 1:\n",
    "                res += self.stats(m[:-1, :])\n",
    "            if info[1] == 1:\n",
    "                res += self.stats(m[:, :-1])\n",
    "\n",
    "        return res     \n",
    "    \n",
    "    \n",
    "    def letter_bigramms(self, word1, word2):\n",
    "    \n",
    "        if not self.language_check(word1, word2):\n",
    "            return [], [], []\n",
    "        \n",
    "        m = self.levenstein_dist(word1, word2)\n",
    "        for i in range(min(m.shape[0], m.shape[1])):\n",
    "            if m[i][i] != 0:\n",
    "                i -= 1\n",
    "                break\n",
    "\n",
    "        m = m[i:, i:]\n",
    "\n",
    "        statistics = self.stats(m)\n",
    "        for k in range(len(statistics)):\n",
    "            statistics[k] = (statistics[k][0]+i, statistics[k][1]+i, statistics[k][2])\n",
    "\n",
    "        statistics = list(set(statistics))  \n",
    "        \n",
    "        change_letter = []\n",
    "        insert_letter = []\n",
    "        delete_letter = []\n",
    "\n",
    "        for info in statistics:\n",
    "\n",
    "            if info[-1] == 0:\n",
    "                change_letter.append((word2[info[1]-1] + word1[info[0]], word2[info[1]-1] + word2[info[1]]))\n",
    "            if info[-1] == 1:\n",
    "                insert_letter.append((word2[info[1]-1] + '*', word2[info[1]-1] + word2[info[1]]))\n",
    "            if info[-1] == -1:\n",
    "                delete_letter.append((word2[info[1]-1] + word1[info[0]], word2[info[1]-1] + '*'))\n",
    "\n",
    "        change_num = 0\n",
    "\n",
    "        while change_num < len(change_letter):\n",
    "    #         print(res[change_num][0])\n",
    "            if change_letter[change_num][0] == change_letter[change_num][1]:\n",
    "                change_letter.pop(change_num)\n",
    "            else:\n",
    "                change_num += 1\n",
    "\n",
    "        return change_letter, insert_letter, delete_letter\n",
    "    \n",
    "    \n",
    "    def query_changes(self, query_pair):\n",
    "    \n",
    "        change_letter_list = []\n",
    "        insert_letter_list = []\n",
    "        delete_letter_list = []\n",
    "\n",
    "        left = query_pair[0].split()\n",
    "        right = query_pair[1].split()\n",
    "\n",
    "        if len(left) == len(right):\n",
    "            for word1, word2 in zip(left, right):\n",
    "                if word1 != word2:\n",
    "\n",
    "                    change_letter, insert_letter, delete_letter = self.letter_bigramms(word1, word2)\n",
    "\n",
    "                    change_letter_list += change_letter\n",
    "                    insert_letter_list += insert_letter\n",
    "                    delete_letter_list += delete_letter\n",
    "\n",
    "        return change_letter_list, insert_letter_list, delete_letter_list\n",
    "    \n",
    "    \n",
    "    def dicts_making(self):\n",
    "        \n",
    "        for query_pair in self.mistakes_with_correctings:\n",
    "\n",
    "            changes, inserts, deletes = self.query_changes(query_pair)\n",
    "\n",
    "            for change in changes:\n",
    "    #             if change[1][0] == 'и' and change[1][1] == 'ь':\n",
    "    #                 print(query_pair)\n",
    "                if change not in self.main_changes_dict.keys():\n",
    "                    self.main_changes_dict[change] = 1\n",
    "                else:\n",
    "                    self.main_changes_dict[change] += 1\n",
    "\n",
    "            for insert in inserts:\n",
    "                if insert not in self.main_inserts_dict.keys():\n",
    "                    self.main_inserts_dict[insert] = 1\n",
    "                else:\n",
    "                    self.main_inserts_dict[insert] += 1\n",
    "\n",
    "            for delete in deletes:\n",
    "                if delete not in self.main_deletes_dict.keys():\n",
    "                    self.main_deletes_dict[delete] = 1\n",
    "                else:\n",
    "                    self.main_deletes_dict[delete] += 1\n",
    "\n",
    "                    \n",
    "    def process_dict(self, main_dict, threshold=100):\n",
    "    \n",
    "        new_dict = dict()\n",
    "\n",
    "        for key in main_dict:\n",
    "            if main_dict[key] >= threshold:\n",
    "                new_dict[key] = main_dict[key]\n",
    "\n",
    "        main_dict = new_dict\n",
    "        print('current main_dict len = ', len(main_dict))\n",
    "\n",
    "        dict_sum = sum(main_dict.values())\n",
    "\n",
    "        for key in main_dict:\n",
    "            main_dict[key] = main_dict[key]/dict_sum\n",
    "\n",
    "        med = np.median(np.array([main_dict[k] for k in main_dict]))\n",
    "        mean = np.mean(np.array([main_dict[k] for k in main_dict]))\n",
    "\n",
    "        return main_dict, med, mean\n",
    "    \n",
    "\n",
    "    def final_changes_dict_maker(self):\n",
    "    \n",
    "        changes_dict = dict()\n",
    "\n",
    "        for key in self.main_changes_dict:\n",
    "            if key[0][1] not in changes_dict.keys():\n",
    "\n",
    "                changes_dict[key[0][1]] = dict()\n",
    "\n",
    "                if key[1][1] not in changes_dict[key[0][1]].keys():\n",
    "                    changes_dict[key[0][1]][key[1][1]] = dict()\n",
    "                    changes_dict[key[0][1]][key[1][1]][key[0][0]] = self.main_changes_dict[key]\n",
    "\n",
    "                else:\n",
    "                    changes_dict[key[0][1]][key[1][1]][key[0][0]] = self.main_changes_dict[key]\n",
    "\n",
    "            else:\n",
    "\n",
    "                if key[1][1] not in changes_dict[key[0][1]].keys():\n",
    "                    changes_dict[key[0][1]][key[1][1]] = dict()\n",
    "                    changes_dict[key[0][1]][key[1][1]][key[0][0]] = self.main_changes_dict[key]\n",
    "\n",
    "                else:\n",
    "                    changes_dict[key[0][1]][key[1][1]][key[0][0]] = self.main_changes_dict[key]\n",
    "\n",
    "        self.main_changes_dict = changes_dict\n",
    "    \n",
    "    \n",
    "    def final_inserts_dict_maker(self):\n",
    "    \n",
    "        inserts_dict = dict()\n",
    "\n",
    "        for key in self.main_inserts_dict:\n",
    "\n",
    "            if key[1][1] not in inserts_dict.keys():\n",
    "\n",
    "                inserts_dict[key[1][1]] = dict()\n",
    "                inserts_dict[key[1][1]][key[0][0]] = self.main_inserts_dict[key]\n",
    "\n",
    "            else:\n",
    "\n",
    "                inserts_dict[key[1][1]][key[0][0]] = self.main_inserts_dict[key]\n",
    "\n",
    "        self.main_inserts_dict = inserts_dict\n",
    "    \n",
    "    \n",
    "    def final_deletes_dict_maker(self):\n",
    "    \n",
    "        deletes_dict = dict()\n",
    "\n",
    "        for key in self.main_deletes_dict:\n",
    "\n",
    "            if key[0][1] not in deletes_dict.keys():\n",
    "\n",
    "                deletes_dict[key[0][1]] = dict()\n",
    "                deletes_dict[key[0][1]][key[0][0]] = self.main_deletes_dict[key]\n",
    "\n",
    "            else:\n",
    "\n",
    "                deletes_dict[key[0][1]][key[0][0]] = self.main_deletes_dict[key]\n",
    "\n",
    "        self.main_deletes_dict = deletes_dict\n",
    "    \n",
    "    \n",
    "    def get_dicts(self):\n",
    "        \n",
    "        return self.main_changes_dict, self.main_inserts_dict, self.main_deletes_dict\n",
    "    \n",
    "    \n",
    "    def get_stats(self, stats='changes'):\n",
    "        \n",
    "        if stats == 'changes':\n",
    "            return self.changes_med, self.changes_mean\n",
    "        \n",
    "        if stats == 'inserts':\n",
    "            return self.inserts_med, self.inserts_mean\n",
    "        \n",
    "        if stats == 'deletes':\n",
    "            return self.deletes_med, self.deletes_mean\n",
    "        \n",
    "        print('bad type')\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, correct = queries_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current main_dict len =  197\n",
      "current main_dict len =  551\n",
      "current main_dict len =  234\n",
      "CPU times: user 12.8 s, sys: 101 ms, total: 12.9 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m_model = Mistakes_model(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 1.09 s, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_model = Language_model(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams, bigrams_freqs_sum = l_model.get_bigrams()\n",
    "words, freqs_sum = l_model.get_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "med, mean = m_model.get_stats('changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_dict, inserts_dict, deletes_dict = m_model.get_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bore_search_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 863 ms, total: 15.8 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b.fit(words, freqs_sum, bigrams, bigrams_freqs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вытащила член взвешивая его в ладони плотоядно такой молодой и уже такой богатый порно рассказ читать\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = 'онреей молохов gecnm гаварят'\n",
    "# q = 'gjujlf'\n",
    "q = 'gfulf d Масве ctujlz'\n",
    "# q = 'ctujlz'\n",
    "q = 'gjhyj ne,t'\n",
    "q = 'порна видо сматрет безплатна'\n",
    "# q = 'игрет в тенес'\n",
    "# q = 'gfuljf'\n",
    "# q = 'google.com'\n",
    "# q = 'смотретьогурец'\n",
    "# q = 'мсква слзам нее верт'\n",
    "# q = 'где можно найти книгу советского горнолыжника тальянова'\n",
    "# q = 'беременною порно'\n",
    "q = 'что входитв стоимиость авиабилетов'\n",
    "q = 'как pfvtybnm gjgkfdjr d eybnfpt c jrjdjq gjldjlrjq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 168 ms, sys: 35.8 ms, total: 204 ms\n",
      "Wall time: 259 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'как заменить поплавок в унитазе с акуловой подводкой'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "b.correct_query(q, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032662884648444216"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'п': 0.004548084829903658,\n",
       " 'л': 0.0010456534318751714,\n",
       " 'р': 0.0019593311878826026,\n",
       " 'а': 0.00292376881922378,\n",
       " 'б': 0.002223282539618083}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deletes_dict['п']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'р': 0.011354580361318027,\n",
       " 'н': 0.008344694499878156,\n",
       " 'к': 0.012625713777637272,\n",
       " 'м': 0.00787048928757253,\n",
       " 'е': 0.001514822205976303,\n",
       " 'г': 0.003536780541779455,\n",
       " 'с': 0.0038068140654534915,\n",
       " 'д': 0.002792541805799793,\n",
       " 'а': 0.0005927565153820316,\n",
       " 'т': 0.006270046696041045,\n",
       " 'п': 0.005868289502282112,\n",
       " 'о': 0.0010142722596536984,\n",
       " 'л': 0.0054533599415146905,\n",
       " 'и': 0.0016004425915314853,\n",
       " 'в': 0.006349080898091983,\n",
       " 'ш': 0.0005005499463226045,\n",
       " 'ф': 0.001508236022472058,\n",
       " 'з': 0.0016992353440951572,\n",
       " 'ь': 0.0008101005710221098,\n",
       " 'б': 0.0026937490532361213,\n",
       " 'й': 0.0009286518740985162,\n",
       " 'х': 0.001448960370933855,\n",
       " 'ч': 0.0010537893606791672,\n",
       " 'я': 0.0003754124597419533,\n",
       " 'ж': 0.00032930917521223975}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inserts_dict['о']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 481 ms, total: 11.9 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('bore_tree.pickle', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 s, sys: 488 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('bore_tree.pickle', 'rb') as f:\n",
    "    data_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'андрей малахов пусть говорят'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.correct_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 148 ms, total: 3.17 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('l_model.pickle', 'wb') as f:\n",
    "    pickle.dump(l_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 160 ms, total: 2.94 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('bigrams.pickle', 'rb') as f:\n",
    "    data_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compress() got an unexpected keyword argument 'mtime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f1e309a2e270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: compress() got an unexpected keyword argument 'mtime'"
     ]
    }
   ],
   "source": [
    "gzip.compress(b, compresslevel=9, mtime=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfbd\n",
      "dfbd\n",
      "dsfb\n",
      "dsfb\n",
      "dfb\n",
      "dfb\n",
      "dfb\n",
      "dfb\n",
      "dfb\n",
      "dfb\n",
      "\\0\n",
      "\\0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-446678a4dd28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MyNewEnviroment/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run  = True\n",
    "\n",
    "while run:\n",
    "\n",
    "    try:\n",
    "        q = input()\n",
    "        print(q)\n",
    "    except EOFError:\n",
    "        run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import struct\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "from copy import copy\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_words(): #opens files and makes dicts of words with posting lists\n",
    "    \n",
    "    files = os.listdir(\"./dataset/\")\n",
    "    urls = dict()\n",
    "    \n",
    "    all_texts_list = list()\n",
    "    dicts = list()\n",
    "    \n",
    "    shift = 0\n",
    "    vocabulary = 0\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        if file.find(\"lenta\") < 0:\n",
    "            continue\n",
    "            \n",
    "        with open(\"./dataset/\" + file, 'rb') as f:\n",
    "            file = f.read()\n",
    "            \n",
    "        f_text = file.decode('utf-8', errors='ignore')\n",
    "        \n",
    "        f_text = re.sub(r'[\\x00\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x01\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x02\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x03\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x04\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x05\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x06\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x07\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x08\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x09\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x1a\\s]+', ' ', f_text)\n",
    "        f_text = re.sub(r'[\\x13\\s]+', ' ', f_text)\n",
    "        \n",
    "        f_text = f_text.lower()\n",
    "        \n",
    "        texts = re.findall(r\"http[s]?://.*?http[s]?://\", f_text)\n",
    "        urls, texts_list = preprocess(texts, urls)\n",
    "        all_texts_list += texts_list\n",
    "        \n",
    "        dicts.append((dict_maker(texts_list), shift))\n",
    "        shift += len(texts_list)\n",
    "        \n",
    "        print(\"Urls number = {}\".format(len(urls.keys())))\n",
    "        \n",
    "    return urls, dicts, all_texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts, urls = dict()): #returns url list and list of clear texts for one file\n",
    "     \n",
    "    text_list = list()\n",
    "    cur_num = len(urls.keys())\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        \n",
    "        text = text[:-7]\n",
    "        url = re.findall(r\"http[s]?:[^ ]*\", text)\n",
    "        text = text[len(url[0]):]\n",
    "        \n",
    "        urls[i + cur_num] = url\n",
    "        text_list.append(text)\n",
    "        \n",
    "    return urls, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(): #fibonacci generator\n",
    "    a, b = 1, 2   \n",
    "    while True:       \n",
    "        yield a\n",
    "        a, b = b, a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_bits(bit_seq, new_bits, length): #add new bits to bit sequence\n",
    "    \n",
    "    if bit_seq == 0:\n",
    "        return new_bits\n",
    "        \n",
    "    bit_seq = bit_seq << 1\n",
    "    bit_seq += 1\n",
    "    \n",
    "    bit_seq = bit_seq << length\n",
    "    bit_seq += new_bits\n",
    "\n",
    "    return bit_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_encode(bit_seq, new_num): #encodes one number and concats it's bits seq to input bits sequence\n",
    "    \n",
    "    code = 0\n",
    "    tmp_code = 1\n",
    "    length = 1\n",
    "    first_rank_flag =1\n",
    "    \n",
    "    while new_num != 0:\n",
    "        gen = fibonacci()\n",
    "        \n",
    "        f = next(gen)\n",
    "        prev = f\n",
    "        \n",
    "        while new_num - f > 0:\n",
    "            \n",
    "            length = length + 1 if first_rank_flag else length\n",
    "            f, prev = next(gen), f\n",
    "            tmp_code = tmp_code << 1\n",
    "      \n",
    "        if new_num - f != 0:\n",
    "            \n",
    "            tmp_code = tmp_code >> 1 \n",
    "            new_num -= prev\n",
    "            length -= 1\n",
    "    \n",
    "        else:\n",
    "            new_num -= f\n",
    "        \n",
    "        first_rank_flag = 0\n",
    "        code += tmp_code\n",
    "        tmp_code = 1\n",
    "\n",
    "    length = len(bin(code))-2\n",
    "    return add_new_bits(bit_seq, code, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_decode(bit_seq): #decodes sequence of bits, returns encoded list\n",
    "    \n",
    "    gen = fibonacci()\n",
    "    lst = list()\n",
    "    num = 0\n",
    "    last = 0\n",
    "    \n",
    "    while bit_seq != 0:\n",
    "        \n",
    "        last, prev = bit_seq & 1, last\n",
    "        bit_seq = bit_seq >> 1\n",
    "        \n",
    "        if last * prev == 1:\n",
    "            \n",
    "            lst.append(num)\n",
    "            \n",
    "            num = 0\n",
    "            prev = 0\n",
    "            last = 0\n",
    "            gen = fibonacci()\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        fib_val = next(gen)\n",
    "        \n",
    "        if last:\n",
    "            num += fib_val\n",
    "\n",
    "    lst.append(num)\n",
    "    lst.reverse()\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_encode_list(lst, b=0): #encode list of numbers\n",
    "\n",
    "    for i in lst:\n",
    "        b = fib_encode(b, i)\n",
    "        \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_index(X, words, idx): # function recieves count vectorizer's matrix, it's vocabulary and word index\n",
    "                                  # returns hashed word, encoded posting list and word frequencies\n",
    "    \n",
    "    docs = np.where(X[:, idx] > 0)[0]\n",
    "\n",
    "    vals = X[:, idx][np.where(X[:, idx] > 0)[0]]\n",
    "    docs += 1 #as 0 can't be encoded\n",
    "\n",
    "    docs_dif = np.zeros(docs.shape[0])\n",
    "    docs_dif[0] = docs[0] \n",
    "    for i in range(1, docs.shape[0]):\n",
    "        docs_dif[i] = docs[i] - docs[i-1]\n",
    "\n",
    "    word = words[idx]\n",
    "\n",
    "    hashed_word = hash(word)\n",
    "\n",
    "    docs_dif_b = fib_encode_list(docs_dif)\n",
    "    vals_b = fib_encode_list(vals)\n",
    "    \n",
    "    return hashed_word, docs_dif_b, vals_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_set(docs_dif): # restores posting list from list of documents differs\n",
    "    \n",
    "    docs_list = np.zeros(len(docs_dif))\n",
    "    docs_list[0] = docs_dif[0]\n",
    "    \n",
    "    for i in range(1, len(docs_dif)):\n",
    "        docs_list[i] = docs_list[i-1] + docs_dif[i]\n",
    "\n",
    "    docs_list = docs_list.astype(int)\n",
    "    \n",
    "    return docs_list - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(elem): # defines priority of element\n",
    "    \n",
    "    if elem == '&':\n",
    "        return (2, '&')\n",
    "    \n",
    "    elif elem == '|':\n",
    "        return (1, '|')\n",
    "    \n",
    "    elif elem == '(':\n",
    "        return (-1, '(')\n",
    "    \n",
    "    elif elem == ')':\n",
    "        return (-2, ')')\n",
    "    \n",
    "    else:\n",
    "        hashed = hash(elem)\n",
    "        return (0, hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poliz_maker(lst): # makes poliz from query list\n",
    "    \n",
    "    res = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    for elem in lst:\n",
    "        \n",
    "        pair = convert(elem)\n",
    "        \n",
    "        if pair[0] == 0:\n",
    "            res.append(pair[1])\n",
    "#             res.append(pair[1])\n",
    "            \n",
    "        elif pair[0] > 0:\n",
    "            while (len(tmp_list) > 0) and (tmp_list[-1][0] >= pair[0]) and (tmp_list[-1][1] != '('):\n",
    "                res.append(tmp_list.pop()[1])\n",
    "            tmp_list.append(pair)\n",
    "            \n",
    "        elif pair[0] < 0:\n",
    "            if pair[1] == '(':\n",
    "                tmp_list.append(pair)\n",
    "            else:\n",
    "                while (len(tmp_list) > 0) and (tmp_list[-1][1] != '('):\n",
    "                    res.append(tmp_list.pop()[1])\n",
    "                tmp_list.pop()\n",
    "    while (len(tmp_list) > 0):\n",
    "        res.append(tmp_list.pop()[1])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_func(f):\n",
    "    if f == '|':\n",
    "        return lambda x, y: x | y\n",
    "    if f == '&':\n",
    "        return lambda x, y: x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_poliz(lst): # processes poliz list, returns list of docs which responds to query\n",
    "    i = 0\n",
    "    while len(lst) != 1:\n",
    "        i += 1\n",
    "\n",
    "        if type(lst[i]) == type('|'):\n",
    "            \n",
    "            arg1 = lst.pop(i-2)\n",
    "            i -= 1\n",
    "            \n",
    "            arg2 = lst.pop(i-1)\n",
    "            i -= 1\n",
    "\n",
    "            func = lst[i]\n",
    "            \n",
    "            if ((len(arg1[0]) > 0) and (arg1[0][0] == -1)) and ((len(arg2[0]) > 0) and (arg2[0][0] == -1)):\n",
    "                \n",
    "                docs = list()\n",
    "                \n",
    "            elif ((len(arg1[0]) > 0) and (arg1[0][0] == -1)):\n",
    "                \n",
    "                docs = arg2[0] if func == '|' else list()\n",
    "                arg1 = (arg1[0], np.zeros(len(arg2[1])))\n",
    "                \n",
    "            elif ((len(arg2[0]) > 0) and (arg2[0][0] == -1)):\n",
    "                \n",
    "                docs = arg1[0] if func == '|' else list()\n",
    "                arg2 = (arg2[0], np.zeros(len(arg1[1])))\n",
    "                \n",
    "            else:\n",
    "                func = initialize_func(func)\n",
    "                docs = list(func(set(arg1[0]), set(arg2[0])))\n",
    "\n",
    "            words = np.zeros(len(docs))\n",
    "            \n",
    "            for j in range(len(docs)):\n",
    "            \n",
    "                words[j] = np.asarray(arg1[1])[np.where(arg1[0] == docs[j])].sum() + \\\n",
    "                           np.asarray(arg2[1])[np.where(arg2[0] == docs[j])].sum()\n",
    "\n",
    "            lst[i] = (docs, words)\n",
    "    \n",
    "    return np.asarray(lst[0][0]), lst[0][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_bit_seqs(b1, b2): # concatination of two bits sequences\n",
    "    \n",
    "    b1 = b1 << 1\n",
    "    b1 += 1\n",
    "    \n",
    "    b1 = b1 << len(bin(b2)) - 2\n",
    "    b1 += b2\n",
    "    \n",
    "    return b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_maker(texts): # makes dict of texts list\n",
    "    \n",
    "    main_dict=dict()\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "\n",
    "    X = X.toarray()\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    for i in range(len(words)):\n",
    "    \n",
    "#         if i %10000 == 0:\n",
    "#             print(i)\n",
    "\n",
    "        res = inverse_index(X, words, i)\n",
    "        if res[0] in main_dict.keys():\n",
    "            \n",
    "            docs = concat_bit_seqs(main_dict[res[0]][0], res[1])\n",
    "            vals = concat_bit_seqs(main_dict[res[0]][1], res[2])\n",
    "            main_dict[res[0]] = (docs, vals)\n",
    "            \n",
    "        else:\n",
    "            main_dict[res[0]] = (res[1], res[2])\n",
    "            \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(string): # converts string representation of query to list\n",
    "    \n",
    "    string = re.sub(r'&', r' & ', string)\n",
    "    string = re.sub(r'\\|', r' | ', string)\n",
    "    string = re.sub(r'\\(', r' ( ', string)\n",
    "    string = re.sub(r'\\)', r' ) ', string)\n",
    "    string = string.split()\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multy_dict_search(dicts, query, urls): # searches documents by query in file's dicts seperately\n",
    "    \n",
    "    expanded_query = preprocess_query(query)\n",
    "    p_list = poliz_maker(expanded_query)\n",
    "    \n",
    "    res = list()\n",
    "    words_num_array = np.zeros(0)\n",
    "    docs_array = np.zeros(0)\n",
    "\n",
    "    for d, shift in dicts:\n",
    "        lst = copy(p_list)\n",
    "\n",
    "        for i in range(len(lst)):\n",
    "            \n",
    "            if type(lst[i]) == type(0):\n",
    "                \n",
    "                if lst[i] in d.keys():\n",
    "                    info = d[lst[i]]\n",
    "                    lst[i] = (docs_set(fib_decode(info[0])), fib_decode(info[1]))\n",
    "                \n",
    "                else:\n",
    "                    lst[i] = ([-1], 0)\n",
    "\n",
    "        docs, words_num = implement_poliz(lst)\n",
    "        docs += shift\n",
    "#         print(\"docs, words = \", docs, words_num)\n",
    "        docs_array = np.hstack((docs_array, docs))\n",
    "        words_num_array = np.hstack((words_num_array, words_num))\n",
    "#         print(docs_array, words_num_array)\n",
    "\n",
    "    docs_array = docs_array[np.argsort(words_num_array)][::-1]\n",
    "    words_num_array = np.sort(words_num_array)[::-1]\n",
    "\n",
    "    for doc_id in docs_array:\n",
    "        res.append((urls[doc_id], np.int(words_num_array[np.where(docs_array==doc_id)][0])))\n",
    "           \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bulean_searcher: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.urls, self.dicts, self.texts = dict_of_words()\n",
    "        \n",
    "    def search(self, s=0, top=-1): # processes general workflow of searcher and prints results\n",
    "        \n",
    "        if type(s) == type(0):\n",
    "            s = input()\n",
    "        self.final = multy_dict_search(self.dicts, s, self.urls)\n",
    "        \n",
    "        if len(self.final) == 0:\n",
    "            print(\"Ничего не найдено, пожалуйста переформулируйте ваш запрос.\")\n",
    "            return\n",
    "        \n",
    "        if top == -1:\n",
    "            top = len(self.final)\n",
    "            \n",
    "        i = -1 \n",
    "        \n",
    "        for i, val in enumerate(self.final):\n",
    "            \n",
    "            url, words_num = val\n",
    "            \n",
    "            if i >= top:\n",
    "                continue\n",
    "            \n",
    "            print(url[0], end='')\n",
    "            print(' '*(55 - len(url[0])), end='')\n",
    "            \n",
    "            if ((words_num % 10 == 2) or (words_num % 10 == 3) or \\\n",
    "                (words_num % 10 == 4)) and (words_num not in range(11, 20)): # just printing right form of word\n",
    "                \n",
    "                print(words_num, \"Совпадения\")\n",
    "                \n",
    "            elif (words_num % 10 == 1):\n",
    "                \n",
    "                print(words_num, \"Совпадение\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                print(words_num, \"Совпадений\")\n",
    "        \n",
    "        i += 1\n",
    "        if ((i % 10 == 2) or (i % 10 == 3) or (i % 10 == 4)): # just printing right form of word\n",
    "\n",
    "            print(\"Найдено {} страницы\".format(i))\n",
    "\n",
    "        elif (i % 10 == 1):\n",
    "\n",
    "            print(\"Найденa {} страницa\".format(i))\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Найдено {} страниц\".format(i))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urls number = 655\n",
      "Urls number = 1266\n",
      "Urls number = 1860\n",
      "Urls number = 2495\n",
      "Urls number = 3119\n",
      "Urls number = 3756\n",
      "Urls number = 4361\n",
      "Urls number = 5006\n"
     ]
    }
   ],
   "source": [
    "bs = bulean_searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lenta.ru/articles/2008/12/04/putin/             49 Совпадений\n",
      "http://lenta.ru/lib/14161216/full                      22 Совпадения\n",
      "http://lenta.ru/conf/tsepliaeva                        10 Совпадений\n",
      "http://lenta.ru/articles/2012/04/18/prokhorova/        8 Совпадений\n",
      "http://lenta.ru/articles/2013/08/16/reaction/          5 Совпадений\n",
      "http://lenta.ru/lib/14159417/full.htm                  5 Совпадений\n",
      "http://lenta.ru/news/2005/09/14/kasianov2/             5 Совпадений\n",
      "http://lenta.ru/lib/14160961/full                      4 Совпадения\n",
      "http://lenta.ru/articles/2006/07/24/hloponin/          4 Совпадения\n",
      "http://lenta.ru/conf/nzubarevich                       3 Совпадения\n",
      "http://lenta.ru/articles/2012/04/30/perm/              3 Совпадения\n",
      "http://lenta.ru/articles/2010/03/30/review/            3 Совпадения\n",
      "http://lenta.ru/articles/2013/10/01/belarus/           2 Совпадения\n",
      "http://bragin-sasha.livejournal.com/                   2 Совпадения\n",
      "http://lenta.ru/articles/2015/08/28/rodina/            2 Совпадения\n",
      "Найдено 15 страниц\n"
     ]
    }
   ],
   "source": [
    "bs.search('политика & (путин | медведев)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lenta.ru/articles/2014/11/07/kino7nov/          8 Совпадений\n",
      "http://lenta.ru/articles/2009/12/16/nokia/             2 Совпадения\n",
      "http://lenta.ru/articles/2011/03/09/zoich/             2 Совпадения\n",
      "Найдено 3 страницы\n"
     ]
    }
   ],
   "source": [
    "bs.search('игра&карты | (теннис & кино)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lenta.ru/news/2012/12/03/ouya/                  2 Совпадения\n",
      "Найденa 1 страницa\n"
     ]
    }
   ],
   "source": [
    "bs.search('игра & приставка ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ничего не найдено, пожалуйста переформулируйте ваш запрос.\n"
     ]
    }
   ],
   "source": [
    "bs.search('(игра | приставка)& обезьяна')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lenta.ru/online/2010/12/08/zhispa               6 Совпадений\n",
      "http://lenta.ru/articles/2009/06/09/infamous/          5 Совпадений\n",
      "http://lenta.ru/news/2013/12/12/fable/                 5 Совпадений\n",
      "http://lenta.ru/news/2011/01/17/cod/                   5 Совпадений\n",
      "http://lenta.ru/news/2012/06/14/playdead/              4 Совпадения\n",
      "Найдено 94 страницы\n"
     ]
    }
   ],
   "source": [
    "bs.search('игра | приставка | обезьяна', top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "игра & футбол | нефть & газ\n",
      "http://lenta.ru/articles/2008/12/04/putin/             13 Совпадений\n",
      "http://lenta.ru/news/2008/08/05/gazprom/               12 Совпадений\n",
      "http://lenta.ru/online/2010/12/08/zhispa               10 Совпадений\n",
      "http://lenta.ru/news/2008/12/18/price/                 9 Совпадений\n",
      "http://lenta.ru/articles/2015/03/06/gavrilov/          6 Совпадений\n",
      "http://lenta.ru/news/2010/05/25/fall/                  5 Совпадений\n",
      "http://lenta.ru/news/2010/06/01/first/                 4 Совпадения\n",
      "http://lenta.ru/articles/2015/01/27/solar/             3 Совпадения\n",
      "http://lenta.ru/news/2009/10/16/trade/                 3 Совпадения\n",
      "http://lenta.ru/news/2006/03/16/marketreview/          2 Совпадения\n",
      "http://lenta.ru/news/2008/01/28/cme/                   2 Совпадения\n",
      "http://lenta.ru/articles/2011/03/09/zoich/             2 Совпадения\n",
      "http://lenta.ru/news/2011/05/25/back/                  2 Совпадения\n",
      "http://lenta.ru/news/2006/04/21/marketrewiew/          2 Совпадения\n",
      "http://lenta.ru/news/2015/05/25/rosneft/               2 Совпадения\n",
      "http://lenta.ru/news/2008/10/10/friedrich/             2 Совпадения\n",
      "http://lenta.ru/articles/2013/05/02/league/            2 Совпадения\n",
      "Найдено 17 страниц\n"
     ]
    }
   ],
   "source": [
    "bs.search() #query from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ничего не найдено, пожалуйста переформулируйте ваш запрос.\n"
     ]
    }
   ],
   "source": [
    "bs.search('путин & трулвыоалов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lenta.ru/articles/2008/12/04/putin/             48 Совпадений\n",
      "http://lenta.ru/lib/14161216/full                      19 Совпадений\n",
      "http://lenta.ru/articles/2013/11/21/pisateli/          14 Совпадений\n",
      "Найдено 197 страниц\n"
     ]
    }
   ],
   "source": [
    "bs.search('путин | трулвыоалов', top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
